{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score,roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: christmas tree farm pictures\\r\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: vastar resources , inc .\\r\\r\\ngary , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\r\\n- c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re : issue\\r\\r\\nfyi - see note below ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: meter 7268 nov allocation\\r\\r\\nfyi .\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0        Subject: christmas tree farm pictures\\r\\r\\n     1\n",
       "1  Subject: vastar resources , inc .\\r\\r\\ngary , ...     1\n",
       "2  Subject: calpine daily gas nomination\\r\\r\\n- c...     1\n",
       "3  Subject: re : issue\\r\\r\\nfyi - see note below ...     1\n",
       "4  Subject: meter 7268 nov allocation\\r\\r\\nfyi .\\...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('email.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8033\n",
       "0    1967\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretraitement et division de la dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 items in training data, 3000 in test data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "cleanup_re = re.compile('[^a-z]+')\n",
    "def cleanup(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = cleanup_re.sub(' ', sentence).strip()\n",
    "    #sentence = \" \".join(nltk.word_tokenize(sentence))\n",
    "    return sentence\n",
    "\n",
    "df[\"Text_Clean\"] = df[\"text\"].apply(cleanup)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "print(\"%d items in training data, %d in test data\" % (len(train), len(test)))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extraction feautures avec TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# To cleanup stop words, add stop_words = STOPWORDS\n",
    "# But it seems to function better without it\n",
    "count_vect = CountVectorizer(min_df = 1, ngram_range = (1, 4))\n",
    "X_train_counts = count_vect.fit_transform(train[\"Text_Clean\"])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_new_counts = count_vect.transform(test[\"Text_Clean\"])\n",
    "X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "y_train = train[\"spam\"]\n",
    "y_test = test[\"spam\"]\n",
    "\n",
    "prediction = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive-bayes(Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " Bayes-naive MULTINOMIAL Rapport: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.28       611\n",
      "           1       0.82      1.00      0.90      2389\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.91      0.58      0.59      3000\n",
      "weighted avg       0.86      0.83      0.78      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Multinomial'] = model.predict(X_test_tfidf)\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" Bayes-naive MULTINOMIAL Rapport: \\n\")\n",
    "print(classification_report(y_test, prediction['Multinomial']))\n",
    "\n",
    "accuracy_mlt = accuracy_score(y_test, prediction['Multinomial'])\n",
    "prediction['Multinomial']= accuracy_mlt * 100\n",
    "\n",
    "print(\"_\"*101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive-bayes(bernouilli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " Bayes-naive Bernouli Rapport: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.13      0.22       611\n",
      "           1       0.82      1.00      0.90      2389\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.87      0.56      0.56      3000\n",
      "weighted avg       0.84      0.82      0.76      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Bernoulli'] = model.predict(X_test_tfidf)\n",
    "\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" Bayes-naive Bernouli Rapport: \\n\")\n",
    "print(classification_report(y_test, prediction['Bernoulli']))\n",
    "\n",
    "accuracy_Ber= accuracy_score(y_test, prediction['Bernoulli'])\n",
    "prediction['Bernouilli']= accuracy_Ber * 100\n",
    "print(\"_\"*101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " KNN Rapport: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       611\n",
      "           1       0.98      0.97      0.98      2389\n",
      "\n",
      "    accuracy                           0.96      3000\n",
      "   macro avg       0.94      0.95      0.94      3000\n",
      "weighted avg       0.96      0.96      0.96      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "prediction['knn'] = knn.predict(X_test_tfidf)\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" KNN Rapport: \\n\")\n",
    "print(classification_report(y_test, prediction['knn']))\n",
    "accuracy_knn = accuracy_score(y_test, prediction['knn'])\n",
    "prediction['knn']= accuracy_knn * 100\n",
    "\n",
    "print(\"_\"*101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " dt Rapport: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       611\n",
      "           1       0.94      0.97      0.95      2389\n",
      "\n",
      "    accuracy                           0.92      3000\n",
      "   macro avg       0.90      0.86      0.88      3000\n",
      "weighted avg       0.92      0.92      0.92      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_tfidf, y_train)\n",
    "prediction['DTree'] = dt.predict(X_test_tfidf)\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" dt Rapport: \\n\")\n",
    "print(classification_report(y_test, prediction['DTree']))\n",
    "accuracy_Dtree = accuracy_score(y_test, prediction['DTree'])\n",
    "prediction['DTree']= accuracy_Dtree * 100\n",
    "print(\"_\"*101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " support vector Rapport: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       611\n",
      "           1       0.80      1.00      0.89      2389\n",
      "\n",
      "    accuracy                           0.80      3000\n",
      "   macro avg       0.40      0.50      0.44      3000\n",
      "weighted avg       0.63      0.80      0.71      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train_tfidf, y_train)\n",
    "predicted_values_SVM = SVM.predict(X_test_tfidf)\n",
    "#print(predicted_values_SVM)\n",
    "accuracy_SVM = accuracy_score(y_test, predicted_values_SVM)\n",
    "prediction['Support Vector Machine (SVM)'] = accuracy_SVM * 100\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" support vector Rapport: \\n\")\n",
    "print(classification_report(y_test, predicted_values_SVM))\n",
    "accuracy_Dtree = accuracy_score(y_test, predicted_values_SVM)\n",
    "predicted_values_SVM = accuracy_Dtree * 100\n",
    "print(\"_\"*101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " regression logistci: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       611\n",
      "           1       0.99      1.00      0.99      2389\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.97      0.98      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg_result = logreg.fit(X_train_tfidf, y_train)\n",
    "prediction['Logistic'] = logreg.predict(X_test_tfidf)\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" regression logistci: \\n\")\n",
    "print(classification_report(y_test, prediction['Logistic']))\n",
    "accuracy_Log = accuracy_score(y_test, prediction['Logistic'])\n",
    "prediction['Logistic']= accuracy_Log * 100\n",
    "print(\"_\"*101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      " random forest: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85       611\n",
      "           1       0.94      1.00      0.97      2389\n",
      "\n",
      "    accuracy                           0.95      3000\n",
      "   macro avg       0.96      0.87      0.91      3000\n",
      "weighted avg       0.95      0.95      0.94      3000\n",
      "\n",
      "_____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators = 100, oob_score = True)\n",
    "# n_estimators - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –ª–µ—Å–µ\n",
    "# oob_score - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –æ–±—Ä–∞–∑—Ü—ã –≤–Ω–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–±–æ–±—â–µ–Ω–∏—è\n",
    "RF.fit(X_train_tfidf, y_train)\n",
    "predicted_values_RF = RF.predict(X_test_tfidf)\n",
    "accuracy_RF = accuracy_score(y_test, predicted_values_RF)\n",
    "prediction['Random Forest'] = accuracy_RF * 100\n",
    "\n",
    "\n",
    "print(\"_\"*101)\n",
    "print(\" random forest: \\n\")\n",
    "print(classification_report(y_test, predicted_values_RF))\n",
    "accuracy_Log = accuracy_score(y_test, predicted_values_RF)\n",
    "predicted_values_RF= accuracy_Log * 100\n",
    "print(\"_\"*101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernouilli</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>96.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTree</td>\n",
       "      <td>92.4667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine (SVM)</td>\n",
       "      <td>79.6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>98.7333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>94.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Algorithms  \\\n",
       "0                   Multinomial   \n",
       "1                     Bernoulli   \n",
       "2                    Bernouilli   \n",
       "3                           knn   \n",
       "4                         DTree   \n",
       "5  Support Vector Machine (SVM)   \n",
       "6                      Logistic   \n",
       "7                 Random Forest   \n",
       "\n",
       "                                          Percentage  \n",
       "0                                                 83  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...  \n",
       "2                                                 82  \n",
       "3                                            96.1333  \n",
       "4                                            92.4667  \n",
       "5                                            79.6333  \n",
       "6                                            98.7333  \n",
       "7                                               94.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1) = plt.subplots(ncols = 1, sharey = True,figsize = (15,5))\n",
    "df = pd.DataFrame(list(prediction.items()),columns = ['Algorithms','Percentage'])\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
